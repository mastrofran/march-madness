{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import Request, urlopen\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def best_weights(feature_df, results_df):\n",
    "#     num_features = len(feature_df.columns[2:-1])\n",
    "#     num_iterations = 2000\n",
    "#     weights=[]\n",
    "#     accuracy_list = []\n",
    "#     weight_list = []\n",
    "#     weights_df = pd.DataFrame()\n",
    "#     results_range=results_df[results_df['Year'].isin(feature_df['Year'].unique())]\n",
    "#     # performance_dict={}\n",
    "#     # print(results_range)\n",
    "#     i=0\n",
    "#     for single_weight in tqdm(range(num_iterations)):\n",
    "#         results_index=[]\n",
    "#         temp_df=pd.DataFrame()\n",
    "#         comparison_column=[]\n",
    "#         weights = np.random.randint(low=-1, high=1, size=num_features).astype(np.float32)\n",
    "#         # weights = np.random.random(num_features)\n",
    "#         # weights /= np.sum(weights)\n",
    "#         fran_weights = feature_df.iloc[:, 2:-3].T.apply(lambda x: x * weights[:-2])\n",
    "#         fran_weights = fran_weights.T\n",
    "#         fran_weights = fran_weights.multiply(feature_df['Strength of Schedule']*weights[-2], axis=0).multiply(feature_df['Last 10 Rating']*weights[-1], axis=0)\n",
    "#         # print(fran_weights)\n",
    "#         # fran_weights = fran_weights.drop(['Strength of Schedule', 'Last 10 Rating'], axis=1)\n",
    "#         fran_weights['Scaled Sum'] = fran_weights.sum(axis=1)\n",
    "#         fran_weights.insert(0,\"Team\",feature_df['Team'].values)\n",
    "#         fran_weights.insert(len(fran_weights.columns), \"Year\", feature_df['Year'].values)\n",
    "    \n",
    "#         for index, row in results_range.iterrows():\n",
    "#             # print(row['Year'])\n",
    "#             # print(index, row)\n",
    "#             team_1_weight = fran_weights[(fran_weights['Team']==row['Team 1']) & (fran_weights['Year']==row['Year'])]['Scaled Sum'].values\n",
    "#             # print(team_1_weight)\n",
    "#             team_2_weight = fran_weights[(fran_weights['Team']==row['Team 2']) & (fran_weights['Year']==row['Year'])]['Scaled Sum'].values\n",
    "#             # print(team_2_weight)\n",
    "#             if team_1_weight > team_2_weight:\n",
    "#                 results_index.append(row['Team 1'])\n",
    "#             else:\n",
    "#                 results_index.append(row['Team 2'])\n",
    "#         temp_df['Winner'] = results_range['Winner']\n",
    "#         temp_df['Predicted Winner'] = results_index\n",
    "#         # print(temp_df)\n",
    "#         comparison_column = np.where(temp_df[\"Winner\"] == temp_df[\"Predicted Winner\"], 1, 0)\n",
    "#         # print(sum(comparison_column))\n",
    "#         accuracy = (sum(comparison_column)/temp_df.shape[0])*100\n",
    "#         # print(performance_dict)\n",
    "#         # print(len(performance_dict))\n",
    "#         # print(accuracy, )\n",
    "#         accuracy_list.append(accuracy)\n",
    "#         weight_list.append(weights)\n",
    "#         i+=1\n",
    "#         pass\n",
    "#     weights_df['Accuracy'] = accuracy_list\n",
    "#     weights_df['Weights'] = weight_list\n",
    "        \n",
    "    \n",
    "        \n",
    "#     return(weights_df)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def best_weights(feature_df, results_df, num_iterations=200, n_jobs=4):\n",
    "    num_features = len(feature_df.columns[2:-1])\n",
    "    results_range = results_df[results_df['Year'].isin(feature_df['Year'].unique())]\n",
    "    \n",
    "    def single_iteration(_):\n",
    "        weights = np.random.uniform(-1, 1, size=num_features).astype(np.float32)\n",
    "        fran_weights = feature_df.iloc[:, 2:-3].mul(weights[2:], axis=1)\n",
    "        fran_weights = fran_weights.mul(feature_df['Strength of Schedule'] * weights[0], axis=0)\n",
    "        fran_weights = fran_weights.mul(feature_df['Last 10 Rating'] * weights[1], axis=0)\n",
    "        fran_weights['Scaled Sum'] = fran_weights.sum(axis=1)\n",
    "        fran_weights['Team'] = feature_df['Team'].values\n",
    "        fran_weights['Year'] = feature_df['Year'].values\n",
    "        \n",
    "        results_index = []\n",
    "        for _, row in results_range.iterrows():\n",
    "            team_1_weight = fran_weights[(fran_weights['Team'] == row['Team 1']) & \n",
    "                                         (fran_weights['Year'] == row['Year'])]['Scaled Sum'].values\n",
    "            team_2_weight = fran_weights[(fran_weights['Team'] == row['Team 2']) & \n",
    "                                         (fran_weights['Year'] == row['Year'])]['Scaled Sum'].values\n",
    "            results_index.append(row['Team 1'] if team_1_weight > team_2_weight else row['Team 2'])\n",
    "        \n",
    "        comparison_column = np.where(results_range['Winner'] == results_index, 1, 0)\n",
    "        accuracy = (np.sum(comparison_column) / len(comparison_column)) * 100\n",
    "        return accuracy, weights\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(single_iteration)(i) for i in tqdm(range(num_iterations)))\n",
    "    accuracy_list, weight_list = zip(*results)\n",
    "    \n",
    "    weights_df = pd.DataFrame({'Accuracy': accuracy_list, 'Weights': weight_list})\n",
    "    return weights_df\n",
    "\n",
    "# Example usage:\n",
    "# feature_df = pd.read_csv('feature_data.csv')\n",
    "# results_df = pd.read_csv('results_data.csv')\n",
    "# optimized_weights_df = best_weights(feature_df, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy                                            Weights\n",
      "0    66.607460  [0.8358988, -0.17095476, -0.078259364, 0.26090...\n",
      "1    69.715808  [-0.46521777, -0.46532875, 0.96826005, 0.65413...\n",
      "2    59.325044  [0.059324943, -0.68438643, -0.49136376, 0.5391...\n",
      "3    69.715808  [0.12179199, 0.33105922, 0.1505765, 0.02593005...\n",
      "4    31.172291  [0.7283951, -0.73771995, 0.54596555, 0.7909973...\n",
      "..         ...                                                ...\n",
      "195  32.149201  [-0.9695793, -0.54342264, 0.013131958, -0.0264...\n",
      "196  65.186501  [0.087644, -0.12549494, 0.26312542, -0.4481043...\n",
      "197  33.392540  [0.71865517, -0.5333386, 0.4882787, -0.3811865...\n",
      "198  48.046181  [0.72703403, 0.628793, -0.014821056, 0.2040344...\n",
      "199  64.653641  [-0.7591636, 0.3163193, -0.8310586, -0.9360029...\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"../data/2007-2025_MBB_Historical-Data.csv\")\n",
    "results_df = pd.read_csv(\"../data/Bracket_Historical_Data.csv\")\n",
    "# print(results_df, features_df)\n",
    "weights_df = best_weights(features_df, results_df)\n",
    "print(weights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df = pd.read_csv(\"../data/2007-2025_MBB_Historical-Data.csv\")\n",
    "# results_df = pd.read_csv(\"../data/Bracket_Historical_Data.csv\")\n",
    "# # print(results_df, features_df)\n",
    "# weights_df = best_weights(features_df, results_df)\n",
    "# print(weights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = weights_df.sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy                                            Weights\n",
      "186  70.515098  [0.85276634, 0.76450694, 0.34348753, 0.0748946...\n",
      "133  70.337478  [0.1720841, 0.9083471, 0.5610719, 0.6562083, -...\n",
      "191  70.337478  [0.032795757, 0.36991316, 0.92986417, -0.05967...\n",
      "50   70.159858  [-0.4728612, -0.96747476, -0.19724093, 0.48246...\n",
      "93   70.159858  [-0.21177976, -0.45977437, -0.48631147, -0.296...\n",
      "..         ...                                                ...\n",
      "17   29.928952  [0.6513682, -0.46935028, 0.09750218, 0.1414670...\n",
      "128  29.928952  [0.8902642, 0.31534868, 0.23546997, 0.01970439...\n",
      "116  29.751332  [-0.6095716, 0.7887073, 0.91320455, 0.27566037...\n",
      "189  29.396092  [-0.20755774, -0.6810471, 0.14661212, -0.25314...\n",
      "46   29.218472  [0.6946765, 0.88744247, -0.9400659, -0.3292428...\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(weights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights_df['Weights'][0]\n",
    "results_index = 0\n",
    "# print(features_df)\n",
    "df = features_df[features_df['Year']==2025]\n",
    "# print(df)\n",
    "fran_weights = df.iloc[:, 2:-3].T.apply(lambda x: x * weights[:-2])\n",
    "fran_weights=fran_weights.T\n",
    "# fran_weights = fran_weights.multiply(df['Strength of Schedule']*weights[-2], axis=0).multiply(df['Last 10 Rating']*weights[-1], axis=0)\n",
    "fran_weights['Scaled Sum'] = fran_weights.sum(axis=1)\n",
    "fran_weights['Team'] = features_df['Team']\n",
    "fran_weights['Year'] = features_df['Year']\n",
    "fran_weights = fran_weights.sort_values(by=['Scaled Sum'], ascending=False)\n",
    "fran_weights.to_csv('Prediction_sum.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "march-madness-z0O2oA0A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
